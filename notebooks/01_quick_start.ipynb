"""
KANFormer - Quick Test Script
=============================
Quick test to verify installation and run a minimal example.
This script runs in ~5-10 minutes and validates the entire pipeline.
"""

import torch
import numpy as np
import warnings
warnings.filterwarnings('ignore')

print("""
╔════════════════════════════════════════════════════════════════════╗
║                    KANFORMER QUICK TEST                            ║
║  This will run a minimal example to verify your installation       ║
║  Expected runtime: 5-10 minutes                                    ║
╚════════════════════════════════════════════════════════════════════╝
""")

# ====================================================================
# STEP 1: CHECK ENVIRONMENT
# ====================================================================
print("\n" + "="*70)
print("STEP 1: CHECKING ENVIRONMENT")
print("="*70)

print("\nPython packages:")
try:
    import torch
    print(f"✓ PyTorch: {torch.__version__}")
except ImportError:
    print("✗ PyTorch not found! Install with: pip install torch")
    exit(1)

try:
    import numpy as np
    print(f"✓ NumPy: {np.__version__}")
except ImportError:
    print("✗ NumPy not found! Install with: pip install numpy")
    exit(1)

try:
    import pandas as pd
    print(f"✓ Pandas: {pd.__version__}")
except ImportError:
    print("✗ Pandas not found! Install with: pip install pandas")
    exit(1)

try:
    import sklearn
    print(f"✓ Scikit-learn: {sklearn.__version__}")
except ImportError:
    print("✗ Scikit-learn not found! Install with: pip install scikit-learn")
    exit(1)

# Check CUDA
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"\n{'✓' if device == 'cuda' else '○'} Device: {device}")
if device == 'cuda':
    print(f"  GPU: {torch.cuda.get_device_name(0)}")
    print(f"  CUDA Version: {torch.version.cuda}")
else:
    print("  Note: Running on CPU (slower but functional)")

print("\n✓ Environment check passed!")

# ====================================================================
# STEP 2: CREATE MINIMAL DATASET
# ====================================================================
print("\n" + "="*70)
print("STEP 2: CREATING MINIMAL DATASET")
print("="*70)

from dataset_preparation import DatasetLoader

loader = DatasetLoader()
X, y = loader.create_synthetic_dataset(n_samples=1000)  # Small dataset for quick test
print(f"✓ Created dataset: {X.shape[0]} samples, {X.shape[1]} features")

# Preprocess
X_train, X_val, X_test, y_train, y_val, y_test = loader.preprocess_data(
    X, y, test_size=0.2, apply_smote=True
)

n_features = X_train.shape[1]
n_classes = len(np.unique(y_train))

print(f"✓ Preprocessed data:")
print(f"  Train: {len(X_train)} samples")
print(f"  Val: {len(X_val)} samples")
print(f"  Test: {len(X_test)} samples")
print(f"  Features: {n_features}")
print(f"  Classes: {n_classes}")

# ====================================================================
# STEP 3: BUILD KNOWLEDGE GRAPH (Optional)
# ====================================================================
print("\n" + "="*70)
print("STEP 3: BUILDING KNOWLEDGE GRAPH (QUICK VERSION)")
print("="*70)

from knowledge_graph import KnowledgeGraph, KGEmbedder

kg = KnowledgeGraph(loader.feature_names[:n_features], n_classes)
kg.construct_from_data(X_train, y_train, correlation_threshold=0.3)

print(f"✓ Knowledge graph created:")
print(f"  Nodes: {kg.graph.number_of_nodes()}")
print(f"  Edges: {kg.graph.number_of_edges()}")

# Train embeddings (reduced epochs for quick test)
embedder = KGEmbedder(kg, embedding_dim=64)
embeddings = embedder.train(n_epochs=20, batch_size=64, learning_rate=0.01)  # Reduced

kg_embeddings = embedder.get_feature_embeddings()
kg_embeddings = torch.FloatTensor(kg_embeddings)

print(f"✓ Knowledge graph embeddings: {kg_embeddings.shape}")

# ====================================================================
# STEP 4: CREATE MODEL
# ====================================================================
print("\n" + "="*70)
print("STEP 4: CREATING KANFORMER MODEL")
print("="*70)

from kanformer_model import create_kanformer

model = create_kanformer(input_dim=n_features, n_classes=n_classes, device=device)
print("✓ Model created successfully")

# ====================================================================
# STEP 5: TRAIN MODEL (QUICK VERSION)
# ====================================================================
print("\n" + "="*70)
print("STEP 5: TRAINING MODEL (QUICK VERSION - 30 EPOCHS)")
print("="*70)

from training_pipeline import KANFormerTrainer, create_data_loaders

# Create data loaders
train_loader, val_loader, test_loader = create_data_loaders(
    X_train, X_val, X_test, y_train, y_val, y_test, batch_size=32
)

# Train (reduced epochs for quick test)
trainer = KANFormerTrainer(model, device=device)
trainer.train(
    train_loader=train_loader,
    val_loader=val_loader,
    n_epochs=30,  # Reduced from 200
    learning_rate=1e-4,
    kg_embeddings=kg_embeddings,
    patience=10,  # Reduced from 20
    save_best=True,
    save_path='quick_test_model.pth'
)

print("✓ Training completed!")

# ====================================================================
# STEP 6: EVALUATE MODEL
# ====================================================================
print("\n" + "="*70)
print("STEP 6: EVALUATING MODEL")
print("="*70)

from training_pipeline import KANFormerEvaluator

evaluator = KANFormerEvaluator(model, device=device)
class_names = ['Science', 'Arts', 'Business', 'Engineering']

metrics, cm, predictions, labels, probs = evaluator.evaluate(
    test_loader=test_loader,
    kg_embeddings=kg_embeddings,
    class_names=class_names
)

print("\n✓ Evaluation completed!")

# ====================================================================
# STEP 7: VERIFY RESULTS
# ====================================================================
print("\n" + "="*70)
print("STEP 7: VERIFICATION")
print("="*70)

print("\nQuick Test Results:")
print(f"  Test Accuracy: {metrics['accuracy']*100:.2f}%")
print(f"  Test F1-Score: {metrics['f1_score']:.4f}")
if metrics['auc'] is not None:
    print(f"  Test AUC: {metrics['auc']:.4f}")

# Sanity checks
success = True
if metrics['accuracy'] < 0.5:
    print("\n⚠ WARNING: Accuracy below 50% - may need more training")
    success = False
elif metrics['accuracy'] < 0.7:
    print("\n○ Note: Accuracy below 70% - expected for quick test with limited epochs")
else:
    print("\n✓ Accuracy looks good for a quick test!")

if metrics['f1_score'] < 0.3:
    print("⚠ WARNING: F1-score very low - check data balance")
    success = False

print("\n" + "="*70)
if success:
    print("✓✓✓ QUICK TEST PASSED! ✓✓✓")
    print("\nYour installation is working correctly!")
    print("\nNext steps:")
    print("  1. Run full training: python main_kanformer.py --dataset synthetic --epochs 200")
    print("  2. Try other datasets: python main_kanformer.py --dataset uci_math")
    print("  3. Compare baselines: python baseline_comparison.py")
else:
    print("⚠⚠⚠ QUICK TEST COMPLETED WITH WARNINGS ⚠⚠⚠")
    print("\nThe installation works, but results are suboptimal.")
    print("This is expected for the quick test (only 30 epochs).")
    print("\nFor better results, run the full training.")

print("="*70)

# ====================================================================
# STEP 8: CLEANUP AND SUMMARY
# ====================================================================
print("\n" + "="*70)
print("TEST SUMMARY")
print("="*70)

print("\nGenerated files:")
print("  ✓ quick_test_model.pth - Trained model checkpoint")

print("\nTest configuration:")
print(f"  Dataset size: 1,000 samples (reduced from 10,000)")
print(f"  Training epochs: 30 (reduced from 200)")
print(f"  KG epochs: 20 (reduced from 100)")
print(f"  Device: {device}")

print("\n" + "="*70)
print("Thank you for testing KANFormer!")
print("For questions: Check README.md or open a GitHub issue")
print("="*70 + "\n")
